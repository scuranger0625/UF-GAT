{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3327ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl                   # 高效能 DataFrame 套件，類似 pandas，但速度更快\n",
    "import torch                          # 深度學習主力套件\n",
    "import torch.nn as nn                 # torch 神經網路子模組\n",
    "import torch.nn.functional as F       # torch 常用函式\n",
    "import networkx as nx                 # 圖論處理/計算中心性用\n",
    "import numpy as np                    # 數值運算\n",
    "from torch_geometric.nn import GATConv    # 圖神經網路 attention layer\n",
    "from torch_geometric.data import Data     # PyG 資料格式\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, roc_curve\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# === 參數區（滑動視窗設定、GAT模型設定、對比學習參數）===\n",
    "file_path = '/content/SAML-D.parquet'    # 檔案位置（Colab上傳後，直接用這個路徑）\n",
    "WINDOW_SIZE = 100000                     # 每個滑動視窗包含幾筆交易\n",
    "STRIDE = 20000                           # 每次滑動多少資料\n",
    "epochs_per_window = 20                   # 每個窗口訓練幾次\n",
    "EMBED_DIM = 16                           # 群組嵌入維度\n",
    "GAT_HIDDEN = 64                          # GAT 隱藏層維度\n",
    "TRIPLET_SAMPLES = 64                     # 每 window 每 epoch 的 triplet 數量\n",
    "TRIPLET_MARGIN = 1.0                     # Triplet Loss 閾值\n",
    "ALPHA = 0.1                              # 對比學習 loss 權重\n",
    "\n",
    "# === Union-Find 動態群組分群結構 ===\n",
    "class UnionFind:\n",
    "    def __init__(self):\n",
    "        self.parent = {}\n",
    "    def find(self, x):\n",
    "        if x not in self.parent:\n",
    "            self.parent[x] = x\n",
    "        if self.parent[x] != x:\n",
    "            self.parent[x] = self.find(self.parent[x])\n",
    "        return self.parent[x]\n",
    "    def union(self, x, y):\n",
    "        xr, yr = self.find(x), self.find(y)\n",
    "        merged = (xr != yr)                  # 如果兩個root不同才會合併\n",
    "        if merged:\n",
    "            self.parent[yr] = xr             # 合併樹 root\n",
    "        return merged                        # 回傳這筆交易是否為新群組合併\n",
    "\n",
    "# === 群組嵌入向量表（每個群組一個嵌入特徵） ===\n",
    "group_embeddings = {}\n",
    "def get_group_embedding(gid):\n",
    "    if gid not in group_embeddings:\n",
    "        group_embeddings[gid] = np.random.normal(size=EMBED_DIM)  # 若沒有則隨機初始化\n",
    "    return group_embeddings[gid]\n",
    "def set_group_embedding(gid, emb):\n",
    "    group_embeddings[gid] = emb\n",
    "\n",
    "# === GAT 多模態圖神經網路模型 ===\n",
    "class UFGAT(nn.Module):\n",
    "    def __init__(self, in_node, in_edge, hidden=64):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_node, hidden, heads=1)       # 第一層GAT\n",
    "        self.gat2 = GATConv(hidden, hidden, heads=1)        # 第二層GAT\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden * 2 + in_edge, 64),            # 將起點/終點 node embedding + edge feature 串起來\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)                                # 輸出一維（邊二元分類）\n",
    "        )\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        h = F.relu(self.gat1(x, edge_index))\n",
    "        h = F.relu(self.gat2(h, edge_index))\n",
    "        h_u, h_v = h[edge_index[0]], h[edge_index[1]]       # 取出邊的兩端 node embedding\n",
    "        edge_input = torch.cat([h_u, h_v, edge_attr], dim=-1)   # 邊的起終點嵌入+邊特徵一起給MLP\n",
    "        return self.mlp(edge_input).squeeze(), h            # 回傳：邊的異常分數, 所有 node embedding\n",
    "\n",
    "# === Triplet 對比學習損失函數（node embedding 對比用） ===\n",
    "def triplet_contrastive_loss(node_emb, triplet_idx, margin=1.0):\n",
    "    if len(triplet_idx) == 0:\n",
    "        return torch.tensor(0.0, device=node_emb.device)\n",
    "    anchor_idx, pos_idx, neg_idx = zip(*triplet_idx)\n",
    "    anchor = node_emb[list(anchor_idx)]\n",
    "    positive = node_emb[list(pos_idx)]\n",
    "    negative = node_emb[list(neg_idx)]\n",
    "    pos_dist = torch.norm(anchor - positive, p=2, dim=-1)       # anchor 和正例的距離\n",
    "    neg_dist = torch.norm(anchor - negative, p=2, dim=-1)       # anchor 和負例的距離\n",
    "    loss = torch.relu(pos_dist - neg_dist + margin).mean()      # Triplet Loss：希望正例更靠近、負例更遠\n",
    "    return loss\n",
    "\n",
    "# === 掃描所有帳戶建立 node index 映射 ===\n",
    "print(\"掃描帳戶全集...\")\n",
    "df = pl.read_parquet(file_path).sort([\"Date\", \"Time\"])         # 讀檔＆排序\n",
    "account_set = set()\n",
    "for row in df.iter_rows(named=True):                           # 建立所有帳戶清單\n",
    "    account_set.add(row[\"Sender_account\"])\n",
    "    account_set.add(row[\"Receiver_account\"])\n",
    "node_idx_map = {acc: i for i, acc in enumerate(sorted(account_set))}   # 每個帳戶對應一個整數編號\n",
    "node_count = len(node_idx_map)\n",
    "print(f\"Total nodes (accounts): {node_count}\")\n",
    "\n",
    "# === 分批滑動視窗訓練主迴圈 ===\n",
    "total_samples = df.height\n",
    "all_pred, all_y_true = [], []\n",
    "model, optimizer, loss_fn = None, None, None\n",
    "global_epoch = 1\n",
    "\n",
    "for start_idx in range(0, total_samples - WINDOW_SIZE + 1, STRIDE):\n",
    "    end_idx = start_idx + WINDOW_SIZE\n",
    "    print(f\"\\n=== 處理第 {start_idx+1} ~ {end_idx} 筆資料（window size: {WINDOW_SIZE}, stride: {STRIDE}） ===\")\n",
    "    window_df = df[start_idx:end_idx]\n",
    "    uf = UnionFind()                                  # 新視窗重置群組\n",
    "    group_graphs = defaultdict(nx.DiGraph)            # 每個群組一張子圖（DAG）\n",
    "    edge_records = []\n",
    "    node_features_cache = np.zeros((node_count, 4))   # 節點特徵暫存\n",
    "    merge_edges, nonmerge_edges = [], []              # 記錄合併/非合併事件邊\n",
    "\n",
    "    # === 建立本 window 內所有交易紀錄及特徵 ===\n",
    "    for idx, row in enumerate(window_df.iter_rows(named=True)):\n",
    "        s, r = row[\"Sender_account\"], row[\"Receiver_account\"]\n",
    "        amount = float(row[\"Amount\"])\n",
    "        paytype = row[\"Payment_type\"]\n",
    "        is_laundering = int(row[\"Is_laundering\"])\n",
    "        merged = uf.union(s, r)                               # Union-Find 分群\n",
    "        gid_s, gid_r = uf.find(s), uf.find(r)\n",
    "        emb_s, emb_r = get_group_embedding(gid_s), get_group_embedding(gid_r)\n",
    "        if merged:\n",
    "            new_emb = (emb_s + emb_r) / 2                    # 合併時取平均（可替換更進階融合）\n",
    "            set_group_embedding(gid_s, new_emb)\n",
    "            set_group_embedding(gid_r, new_emb)\n",
    "            merge_flag = 1\n",
    "            merge_edges.append((node_idx_map[s], node_idx_map[r]))\n",
    "        else:\n",
    "            merge_flag = 0\n",
    "            nonmerge_edges.append((node_idx_map[s], node_idx_map[r]))\n",
    "        group_graphs[gid_s].add_edge(s, r, weight=amount)    # 群組子圖持續擴展\n",
    "        G = group_graphs[gid_s]\n",
    "        group_size = G.number_of_nodes()\n",
    "        # 若群組大於5才計算中心性指標（避免噪聲）\n",
    "        if group_size >= 5:\n",
    "            closeness = nx.closeness_centrality(G)\n",
    "            betweenness = nx.betweenness_centrality(G)\n",
    "            avg_closeness = np.mean(list(closeness.values()))\n",
    "            avg_betweenness = np.mean(list(betweenness.values()))\n",
    "        else:\n",
    "            avg_closeness = 0\n",
    "            avg_betweenness = 0\n",
    "        # 節點特徵（只存degree+merge_flag, 你可擴充）\n",
    "        node_features_cache[node_idx_map[s], 0] = G.degree(s)\n",
    "        node_features_cache[node_idx_map[r], 0] = G.degree(r)\n",
    "        node_features_cache[node_idx_map[s], 1] = merge_flag\n",
    "        node_features_cache[node_idx_map[r], 1] = merge_flag\n",
    "        group_sim = np.linalg.norm(emb_s - emb_r)            # 群組嵌入間距\n",
    "        # 邊特徵（多模態，含金額log、支付方式one-hot、中心性、群組大小、合併flag、嵌入距離）\n",
    "        edge_feat = [\n",
    "            np.log1p(amount),\n",
    "            1 if paytype == \"Cash Deposit\" else 0,\n",
    "            1 if paytype == \"Credit card\" else 0,\n",
    "            1 if paytype == \"Cross-border\" else 0,\n",
    "            1 if paytype == \"Cheque\" else 0,\n",
    "            avg_closeness, avg_betweenness, group_size,\n",
    "            merge_flag,\n",
    "            group_sim\n",
    "        ]\n",
    "        edge_records.append([node_idx_map[s], node_idx_map[r], edge_feat, is_laundering])\n",
    "    print(f\"本窗口樣本數: {len(edge_records)}，正樣本: {np.sum([rec[3] for rec in edge_records])}\")\n",
    "\n",
    "    # === 將資料整理成 PyTorch Geometric 格式 ===\n",
    "    edges = np.array([[rec[0], rec[1]] for rec in edge_records]).T\n",
    "    edge_features = np.array([rec[2] for rec in edge_records])\n",
    "    labels = np.array([rec[3] for rec in edge_records])\n",
    "    node_features = node_features_cache\n",
    "    data = Data(\n",
    "        x=torch.tensor(node_features, dtype=torch.float),\n",
    "        edge_index=torch.tensor(edges, dtype=torch.long),\n",
    "        edge_attr=torch.tensor(edge_features, dtype=torch.float),\n",
    "        y=torch.tensor(labels, dtype=torch.float)\n",
    "    )\n",
    "\n",
    "    # === 處理正負樣本不均，算加權 ===\n",
    "    n_pos = np.sum(labels == 1)\n",
    "    n_neg = np.sum(labels == 0)\n",
    "    pos_weight = torch.tensor([n_neg / n_pos]) if n_pos > 0 else torch.tensor([1.0])\n",
    "    print(f\"正負樣本分布：正樣本={n_pos}，負樣本={n_neg}，pos_weight={pos_weight.item():.2f}\")\n",
    "\n",
    "    # === 初始化/重用模型與優化器 ===\n",
    "    if model is None:\n",
    "        model = UFGAT(in_node=node_features.shape[1], in_edge=edge_features.shape[1], hidden=GAT_HIDDEN)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    # === 取出 Triplet 對比樣本組 ===\n",
    "    def get_triplet_samples(merge_edges, nonmerge_edges, k=TRIPLET_SAMPLES):\n",
    "        triplets = []\n",
    "        if len(merge_edges) == 0 or len(nonmerge_edges) == 0:\n",
    "            return triplets\n",
    "        sample_merges = random.choices(merge_edges, k=min(k, len(merge_edges)))\n",
    "        sample_nonmerges = random.choices(nonmerge_edges, k=min(k, len(nonmerge_edges)))\n",
    "        for (a, p), (n1, n2) in zip(sample_merges, sample_nonmerges):\n",
    "            triplets.append((a, p, n1))          # (anchor, positive, negative)\n",
    "        return triplets\n",
    "\n",
    "    # === 訓練模型 ===\n",
    "    for epoch in range(epochs_per_window):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out, node_emb = model(data.x, data.edge_index, data.edge_attr)  # GAT forward\n",
    "        loss = loss_fn(out, data.y)                                    # 二元分類 loss\n",
    "        triplet_idx = get_triplet_samples(merge_edges, nonmerge_edges, TRIPLET_SAMPLES)\n",
    "        contrastive = triplet_contrastive_loss(node_emb, triplet_idx, margin=TRIPLET_MARGIN)\n",
    "        total_loss = loss + ALPHA * contrastive                        # 總損失：分類+對比\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            pred_prob = torch.sigmoid(model(data.x, data.edge_index, data.edge_attr)[0]).cpu().numpy()\n",
    "            pred_label = (pred_prob > 0.5).astype(int)\n",
    "            y_true_np = data.y.cpu().numpy()\n",
    "            try:\n",
    "                auc_val = roc_auc_score(y_true_np, pred_prob)\n",
    "            except:\n",
    "                auc_val = float('nan')\n",
    "            f1_val = f1_score(y_true_np, pred_label, zero_division=0)\n",
    "            precision_val = precision_score(y_true_np, pred_label, zero_division=0)\n",
    "            recall_val = recall_score(y_true_np, pred_label, zero_division=0)\n",
    "            acc_val = accuracy_score(y_true_np, pred_label)\n",
    "        print(f\"Win {start_idx//STRIDE+1} | Epoch {global_epoch} - Loss: {loss.item():.4f} | Contrast: {contrastive.item():.4f} | \"\n",
    "              f\"AUC: {auc_val:.4f} | F1: {f1_val:.4f} | Pre: {precision_val:.4f} | Rec: {recall_val:.4f} | Acc: {acc_val:.4f}\")\n",
    "        global_epoch += 1\n",
    "\n",
    "    # === 本 window 評估及顯示 ROC ===\n",
    "    with torch.no_grad():\n",
    "        pred = torch.sigmoid(model(data.x, data.edge_index, data.edge_attr)[0]).cpu().numpy()\n",
    "        y_true_np = data.y.cpu().numpy()\n",
    "    all_pred.append(pred)\n",
    "    all_y_true.append(y_true_np)\n",
    "    fpr, tpr, thresholds = roc_curve(y_true_np, pred)\n",
    "    f1s = [f1_score(y_true_np, (pred > thr).astype(int)) for thr in thresholds]\n",
    "    best_idx = int(np.argmax(f1s))\n",
    "    best_thr = thresholds[best_idx]\n",
    "    best_pred_label = (pred > best_thr).astype(int)\n",
    "    auc_val = roc_auc_score(y_true_np, pred)\n",
    "    f1_val = f1_score(y_true_np, best_pred_label)\n",
    "    precision_val = precision_score(y_true_np, best_pred_label, zero_division=0)\n",
    "    recall_val = recall_score(y_true_np, best_pred_label, zero_division=0)\n",
    "    acc_val = accuracy_score(y_true_np, best_pred_label)\n",
    "    print(f\"窗口ROC -- Best Threshold (max F1): {best_thr:.4f}\")\n",
    "    print(\"AUC:      \", auc_val)\n",
    "    print(\"F1:       \", f1_val)\n",
    "    print(\"Precision:\", precision_val)\n",
    "    print(\"Recall:   \", recall_val)\n",
    "    print(\"Accuracy: \", acc_val)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve (Win {start_idx//STRIDE+1})\")\n",
    "    plt.legend(loc='lower right')\n",
    "    metrics_text = f\"AUC={auc_val:.3f}\\nF1={f1_val:.3f}\\nPre={precision_val:.3f}\\nRec={recall_val:.3f}\\nThr={best_thr:.3f}\"\n",
    "    plt.gca().text(0.02, 0.98, metrics_text, fontsize=11, verticalalignment='top', horizontalalignment='left', bbox=dict(facecolor='white', alpha=0.7))\n",
    "    plt.show()   # ⭐ 只顯示，不存圖\n",
    "\n",
    "# === 合併全體結果，計算全局微平均ROC及F1 ===\n",
    "all_pred = np.concatenate(all_pred)\n",
    "all_y_true = np.concatenate(all_y_true)\n",
    "fpr, tpr, thresholds = roc_curve(all_y_true, all_pred)\n",
    "f1s = [f1_score(all_y_true, (all_pred > thr).astype(int)) for thr in thresholds]\n",
    "best_idx = int(np.argmax(f1s))\n",
    "best_thr = thresholds[best_idx]\n",
    "best_pred_label = (all_pred > best_thr).astype(int)\n",
    "auc_val = roc_auc_score(all_y_true, all_pred)\n",
    "f1_val = f1_score(all_y_true, best_pred_label)\n",
    "precision_val = precision_score(all_y_true, best_pred_label, zero_division=0)\n",
    "recall_val = recall_score(all_y_true, best_pred_label, zero_division=0)\n",
    "acc_val = accuracy_score(all_y_true, best_pred_label)\n",
    "print(\"\\n--- 全體微平均(Global)最佳指標 ---\")\n",
    "print(f\"Best Threshold (max F1): {best_thr:.4f}\")\n",
    "print(\"AUC:      \", auc_val)\n",
    "print(\"F1:       \", f1_val)\n",
    "print(\"Precision:\", precision_val)\n",
    "print(\"Recall:   \", recall_val)\n",
    "print(\"Accuracy: \", acc_val)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, label=f'Global ROC')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(f\"Global ROC Curve (Micro Avg.)\")\n",
    "plt.legend(loc='lower right')\n",
    "metrics_text = f\"AUC={auc_val:.3f}\\nF1={f1_val:.3f}\\nPre={precision_val:.3f}\\nRec={recall_val:.3f}\\nThr={best_thr:.3f}\"\n",
    "plt.gca().text(0.02, 0.98, metrics_text, fontsize=13, verticalalignment='top', horizontalalignment='left', bbox=dict(facecolor='white', alpha=0.7))\n",
    "plt.show()  # ⭐ 只顯示，不存圖\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
